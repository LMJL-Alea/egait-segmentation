---
title: "Gait Segmentation Model for Rotation Time Series Collected by a Wearable Sensor using Machine Learning"
author:
  - name: Manon Simonot
    corresponding: true
    email: manon.simonot@univ-nantes.fr
    affiliations:
      - name: Department of Mathematics Jean Leray, UMR CNRS 6629, Nantes University
  - name: Lise Bellanger
    email: lise.bellanger@univ-ubs.fr
    affiliations:
      - name: Lab-STICC Laboratory, UMR CNRS 6285, South Brittany University
  - name: Aymeric Stamm
    email: aymeric.stamm@cnrs.fr
    affiliations:
      - name: Department of Mathematics Jean Leray, UMR CNRS 6629, Nantes University
date: last-modified
date-modified: last-modified
abstract: >+
  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur posuere vestibulum facilisis. Aenean pretium orci augue, quis lobortis libero accumsan eu. Nam mollis lorem sit amet pelSlowsque ullamcorper. Curabitur lobortis libero eget malesuada vestibulum. Nam nec nibh massa. PelSlowsque porttitor cursus tellus. Mauris urna erat, rhoncus sed faucibus sit amet, venenatis eu ipsum.
keywords: [key1, key2, key3]
citation:
  type: article-journal
  container-title: "Computo"
  doi: "xxxx"
  url: https://computo.sfds.asso.fr/template-computo-quarto
  publisher: "Société Française de Statistique"
  issn: "2824-7795"
bibliography: references.bib
github-user: computorg
repo: "template-computo-r"
draft: true # set to false once the build is running
published: false # will be set to true once accepted
format:
  computo-html: default
  computo-pdf:
    cite-method: biblatex
    biblatexoptions: "sorting=none"
tbl-cap-location: bottom
header-includes:
  - \usepackage{longtable}
  - \usepackage{hhline}
  - \usepackage{enumitem}
---

# Introduction

## Context

### Gait analysis

Study of the human gait has been shown to be important in various health applications, such as study of general health in elderly populations [@beauchet2016poor]. Wearable sensors are increasingly used for gait analysis as they are smaller, cheaper and more convenient than other methods such as motion capture systems or mats containing pressure sensors.

A walking cycle is defined as a stride, which is composed of two steps. More formally, a stride is the set of movements performed between two consecutive contacts of the heel of the same foot with the ground. The goal of our method is to segment the gait as cycles to extract strides. This allows further study of the gait, like spatio-temporal parameters computation.

More precisely, a stride is divided in two phases: the stance phase and the swing phase. The stance phase lasts generally 60% of the entire stride. Different events are happening during a stride (see @fig-walking-cycle) and the focus in this work is the Heel-Strike event which will be the segmentation marker.

![Events and phases of a typical gait cycle. [^jacquelin-perry]](images/walking-cycles.png){#fig-walking-cycle width=400}

[^jacquelin-perry]: Figure annotated from Jaquelin Perry's one on [Wikipedia](https://commons.wikimedia.org/wiki/File:GaitCycle_by_JaquelinPerry.jpg).

### Unit quaternions

Unit quaternions can be used to represent the 3D rotation of an object over time [@hamilton1844;@voight2021quaternion]. This representation has several advantages, as it is a rather compressed representation containing only four values and avoiding the gimbal lock problem presents in other representations. Unit quaternions were therefore chosen as the data type returned by the sensor.

Quaternions are four-dimensional vectors denoted as $\mathbf{q} = \left( q_w, q_x, q_y, q_z \right)$, but can also be viewed as hypercomplex numbers of rank 4. Unit quaternions have a norm of 1 and can encode a 3D rotation with a rotation angle $\theta \in [0, 2\pi]$ and a rotation axis $\mathbf{u} = (u_x, u_y, u_z) \in S^2$, where $S^2$ is the 2-sphere, using the following formula:

$$
\mathbf{q} = \text{cos}\left(\frac{\theta}{2}\right) + \left(u_x i + u_y j + u_z k \right) \text{sin}\left(\frac{\theta}{2}\right)
$$ {#eq-quaternions}

with :

- $i$, $j$, and $k$ generalizing the imaginary number $i$, as $i^2=j^2=k^2=ijk=-1$.
- $||\mathbf{q}|| = \sqrt{\mathbf{qq}^t} = 1$.

The set of unit quaternions, denoted $\mathbb{H}_u$, possesses interesting properties. The quaternions $\mathbf{q}$ and $-\mathbf{q}$ represent the same rotation. The group is equipped with an identity element $\mathbf{q}^{(0)} = (1,0,0,0)$ which corresponds to the identity rotation, such that $\mathbf{q} \mathbf{q}^{(0)} = \mathbf{q}^{(0)}\mathbf{q} = \mathbf{q}$.

It is possible to use the geodesic distance $d_g$ between two quaternions $\mathbf{q}_1$ and $\mathbf{q}_2$ to define a metric space $(\mathbb{H}_u, d_g)$, with:

$$
d_g (\mathbf{q}_1, \mathbf{q}_2) = ||\text{log}(\mathbf{q}_1^{-1} \mathbf{q}_2)||
$$ {#eq-dist-geodesique}

In this application, the sensor orientation is the rotation between the reference frame of origin, here the Earth's reference frame $R_f=(f_1, f_2, f_3)$ and its own reference frame $R_s=(s_1, s_2, s_3)$ formed by the accelerometer, gyroscope, and magnetometer (see @fig-sensor-axis).

![Sensor reference and axis. [@drouin2023semi]](images/sensor-axis.png){#fig-sensor-axis width=200}

Therefore, the IMU returns unit quaternion time-series allowing the study of the 3D hip rotation over time, as four-component vectors.



## State of the art

In the past, several methods for gait cycle segmentation have been studied based on signals recorded from wearable sensors placed on different parts of the body. We try in this part to give an overview of proposed methods by grouping them into categories, with variations related to the position of sensors on the body, the type of sensor measurement system used, and the characteristics of the signal.

Search for feature points: Peak Detection and zero-crossing

: Peak detection algorithms exploit the semi-periodic properties of the gait cycle, assuming that specific events during a gait cycle typically match the maxima or minima of a recorded signal. Several algorithms based on this method have been developed. Spatio-temporal gait parameters have been determined from the acceleration signal of a sensor by using peak detection and zero-crossing methods to identify stride cycles [@zijlstra2003assessment]. Some peak detection algorithms have been developed to work on any kind of signal [@jiang2017robust] or are specifically implemented to work to detect gait events on a signal, often Heel-Strike on acceleration data [@lueken2019peak]. Most methods detect Heel-Strike and Toe-off events by identifying minima, maxima or zero-crossing of acceleration time series [@gonzalez2010real;@mariani2013quantitative;@panebianco2018analysis]. These events can be called Initial Contact and Terminal Contact and have also been identified on the foot inclination angle in the sagittal plane [@nazarahari2022foot].

Analysis of dynamic properties: Wavelet Transform

: To detect gait events in recorded signals, another used method is wavelet transform because it allows detection of a specified frequency at a specified time. This method has been used to detect Heel-Strike and Toe-off events on an angular velocity signal by using multi-resolution wavelet decomposition [@aminian2002spatio]. The signal is decomposed into wavelet packages, using high-scale and low-scale filters. In @mccamley2012enhanced, the signal of the vertical acceleration is smoothed by integrating and then differentiating using a Gaussian Continuous Wavelet Transform (CTW). Events are found on minima and maxima of the differentiated signal. Furthemore, a method called Sparsity-assisted wavelet denoising (SWAD) has been developed to segment the signal in three events: midstance, toe-off and heel-strike [@prateek2019gait]. It uses a combination of linear time invariant filters, wavelets and sparsity based methods to extract a coefficient vector of Discrete Wavelet Transform (DTW). That generates a sparse template of moving segments of gyroscope measurements.

Pattern-matching: Dynamic Time Warping (DTW)

: To segment signals, another method is pattern-matching. Dynamic Time Warping is widely used for this matter. It allows identification of patterns with different length and it matches signals non-linearly. Thus it is commonly used to evaluate the similarity between time series. This method has been used on an acceleration signal to identify gait cycles [@ghersi2020gait]. In another study, multi-dimensional subsequence DTW (msDTW) was used to segment strides using informations from different axes of an accelerometer and a gyroscope at the same time [@barth2015stride].

Hidden Markov Models

: Hidden Markov Models (HMMs) are machine learning models that can be used to simultaneously segment and classify data. In gait analysis, hidden states of the HMM are viewed as activity classes or gait phases. Continuous HMM with Gaussian mixture model are often used to model the outputs. Each cycle can be modeled with a circular left to right HMM, included in a more global HMM model to classify walking activities [@panahandeh2013continuous]. Other algorithms have the goal of detecting four gait events which are Heel-Strike, Flat-Foot, Heel-Off and Toe-Off. They use a four state left to right HMM with observations following a multivariate Gaussian distributions [@mannini2011hidden;@garcia2022adaptive]. Hierarchical HMMs have shown to perform better than Peak detection and Dynamic Time Warping algorithms on walking data [@haji2018segmentation].

Other Machine Learning methods

: Many studies on gait analysis use wearable sensors and machine learning. A study showed that most used methods for this purpose are SVM and CNN, and are largely used to detect diseases or recognize activities when analyzing gait data [@saboor2020latest]. SVM divides a set of objects into classes with widest possible margin at the hyperplane boundaries. Neural Networks use interconnected nodes organized in layers to process informations and learn patterns through back-propagation and make predictions using activation functions.

: Studies show good results when using machine learning to classify gait of patients having trouble walking, for instance patients with Parkinson Disease [@tahir2012parkinson;@wahid2015classification], or to extract gait parameters [@rampp2014inertial;@hannink2016sensor]. These studies mostly use Artificial Neural Networks but do not address the problem of the segmentation of the signal recorded by the sensors. Similarly, in @farah2019design, a logistic regression tree is used to classify gait phases in a stride but not to directly segment the signal into strides.

: For the segmentation matter, Recurrent Neural Networks have shown good results for identifying Heel-Strike and Toe-off events with pressure sensors, accelerations and Euler angles [@prado2019gait]. Another study compared unsupervised machine learning (k-means) with supervised one (SVM and CNN), showing that CNNs were performing the best to predict stance and swing phases [@potluri2019machine]. Lastly, in another study, 24 time series from three sensors’ accelerometers and gyroscopes were used as input into a 6 layers CNN to estimate the likelihood of the corresponding input sample, given a specific gait event [@gadaleta2019deep]. For instance, the signal can be segmented with the initial contact of the right foot if this gait event is chosen in the model. This method was shown to perform better than a Wavelet Transform algorithm.

In our research, we did not find studies using a decision tree model to segment the sensor signal into strides.

# Proposed segmentation model

## Data acquisition

A wearable sensor was used to record the hip rotation. It contains an acceleromerer, a gyroscope and a magnetometer. Subjects were wearing the sensor on their right hip (see @fig-sensor-position). The frequence of the sensor is 100Hz. With this device, the data acquired is in the form of quaternion time-series, representing the 3D rotation of the hip over time.

![Sensor positionned on the right hip.](images/sensor-position.png){#fig-sensor-position width=150}


Furthemore, during acquisitions, subjects were walking on the GAITRite© mat, the gold standard in gait analysis [@Menz2004]. It implies that subject were walking approximately 9 meters. This device gives the times where the subjects touch the ground at each step thanks to pressure sensors in the mat, meaning that these times can be used to know when the Heel-Strike event actually happened. This data is then used to train the model. To use the two devices simultaneously, they were started at the same time by the same person, allowing a good synchronization between devices.

Six subjects have been included in this study, with different walking speed (see @tbl-subjects). 

<!-- +-----+--------+-------+-------------------------+ -->
<!-- | ID  | Gender | Age   | Speed (cm/s)            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MBA | M      | 50-60 | - Slow : 60             | -->
<!-- |     |        |       | - Intermediate : 116    | -->
<!-- |     |        |       | - Normal : 145          | -->
<!-- |     |        |       | - Fast : 199            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MBO | F      | 20-30 | - Slow : 73             | -->
<!-- |     |        |       | - Intermediate : 122    | -->
<!-- |     |        |       | - Normal : 145          | -->
<!-- |     |        |       | - Fast : 188            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MSI | F      | 20-30 | - Slow : 67             | -->
<!-- |     |        |       | - Intermediate : 115    | -->
<!-- |     |        |       | - Normal : 148          | -->
<!-- |     |        |       | - Fast : 179            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MTR | M      | 20-30 | - Slow : 77             | -->
<!-- |     |        |       | - Normal : 132          | -->
<!-- |     |        |       | - Fast : 185            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | NNE | F      | 20-30 | - Slow :  57            | -->
<!-- |     |        |       | - Intermediate : 116    | -->
<!-- |     |        |       | - Normal : 147          | -->
<!-- |     |        |       | - Fast : 190            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | TDE | M      | 50-60 | - Slow : 61             | -->
<!-- |     |        |       | - Normal : 120          | -->
<!-- |     |        |       | - Fast : 193            | -->
<!-- +-----+--------+-------+-------------------------+ -->

<!-- : Summary of subjects and walking speeds used for the model. {#tbl-subjects} -->


::: {#tbl-subjects}

```{r}
data.frame(
  id = c("MBA", "MBO", "MSI", "MTR", "NNE", "TDE"),
  gender = c("M", "F", "F", "M", "F", "M"),
  age = c("50-60", "20-30", "20-30", "20-30", "20-30", "50-60"),
  slow = c(60, 73, 67, 77, 57, 61),
  intermediate = c(116, 122, 115, NA, 116, NA),
  preferential = c(145, 145, 148, 132, 147, 120),
  fast = c(199, 188, 179, 185, 190, 193)
) |> 
  gt::gt() |> 
  gt::tab_spanner(
    label = "Walking speed (cm/s)",
    columns = c(slow, intermediate, preferential, fast)
  ) |> 
  gt::cols_label(
    id = "ID",
    gender = "Gender",
    age = "Age range (years)",
    slow = "Slow",
    intermediate = "Intermediate",
    preferential = "Preferential",
    fast = "Fast"
  ) |> 
  gt::sub_missing() |> 
  gt::opt_stylize(style = 6, color = 'gray') |> 
  gt::tab_options(
    column_lab
  )
```

Summary of subjects and walking speeds used for the model.

:::


## Data presentation

Sensor data

: As mentioned before, the sensor returns unit quaternion time-series representing the rotation of the hip over time, allowing visualization of each coordinate time-serie (see @fig-timeserie). It is important to note that on this figure, the walking cycles are clearly apparent and consistent over time, as it represents a healthy gait. This is not the case for subjects having gait disorders, which is why we develop a method more complex than peak detection.

![Data returned by the wearable sensor.](images/time-serie.png){#fig-timeserie width=350}

Sensor data preprocessing 

: A centring step is applied on the quaternion time-series to center them around a mean. Supposing we have $n$ time-series $\mathbf{Q}_1, \dots, \mathbf{Q}_n$ on the same time grid $t_1, \dots, t_p$, we can write $\mathbf{Q}_i(t_k) = \mathbf{q}_{ik} \in \mathbb{H}_u$, with $i \in [\![ 1, n ]\!]$ et $k \in [\![ 1, p ]\!]$. We use the Fréchet mean associated to the geodesic distance $d_g$ (see @eq-dist-geodesique) to compute the mean of each quaternion $\mathbf{q}_{1k}, \dots, \mathbf{q}_{nk}$ for each time $t_k$. 

: $$
\mathbf{q}_k^{(m)} = \mathbf{Q}^{(m)} (t_k) = \underset{q \in \mathbb{H}_u}{\mathrm{argmin}} \sum_{i=1}^n d_g^2(\mathbf{q}_{ik}, \mathbf{q}), \hspace{5mm} k \in [\![ 1, p ]\!]
$$ {#eq-mean-qts}

: The centered time-series $\mathbf{Q}_1^{(c)}, \dots, \mathbf{Q}_n^{(c)}$ can then be computed.

: $$
\mathbf{q}_{ik}^{(c)} = \mathbf{Q}_i^{(c)} (t_k) = \left( \mathbf{q}_k^{(m)} \right)^{-1} \mathbf{q}_{ik}, \hspace{5mm} k \in [\![ 1, p ]\!],\hspace{2mm}  i \in [\![ 1, n ]\!]
$$ {#eq-centring-qts}

: The other pre-processing step is to switch to a functional representation using cubic splines to be able to compute derivatives [@ramsay2005].


Pressure mat data

: The GAITRite© mat returns directly spatio-temporal parameters such as stride duration, stride length or speed. The key parameter in our study is the Heel-Strike exact time. Since the two devices were triggered simultaneously, the same time range is used to associate the Heel-Strike event with a time on the sensor time-series. More precisely, each time of the time-series will be classified between two classes: *Heel-Strike* or *other times*. This method rises a class imbalance challenge that will be adressed later in the article.


## Feature space

To implement a machine learning model, we build a feature space containing variables characterizing the hip rotation over time.

Angular velocity and acceleration

: Supposing we can compute first and second derivatives of a quaternion time-series over time, we can compute angular velocity and acceleration [@narayan2017]. The angular velocity $\pmb{\Omega}$ is a vector which has for direction the axis of rotation and for quantity the angular velocity.

: $$
\pmb{\Omega} = 2 \mathbf{q}^{-1} \dot{\mathbf{q}} \hspace{3mm} \text{with} \hspace{3mm} \dot{\mathbf{q}} = \frac{d \mathbf{q}}{dt} = \frac{1}{2} \mathbf{q} \hspace{1mm} \pmb{\Omega}
$$ {#eq-angular-vel}

: Similarly, the angular acceleration $\dot{\pmb{\Omega}}$ is the angular velocity derivative.

: $$
\dot{\pmb{\Omega}} = 2 \left( \mathbf{q}^{-1} \ddot{\mathbf{q}} - (\mathbf{q}^{-1}\dot{\mathbf{q}})^2 \right) \hspace{3mm} \text{with} \hspace{3mm} \ddot{\mathbf{q}} = \frac{d^2 \mathbf{q}}{dt^2} = \frac{1}{2} \left( \dot{\mathbf{q}} \hspace{1mm}  \pmb{\Omega} + \mathbf{q} \hspace{1mm}  \dot{\pmb{\Omega}} \right)
$$ {#eq-angular-acc}

Euler angles

: The angles named Roll, Pitch and Yaw represent rotations around the three principal axies. Their computation is done using the quaternion time-series, with the following rotation matrix to go from the quaternion $\mathbf{q} = (q_w, q_x, q_y, q_z)$ to the angles.

$$
\begin{bmatrix}
\text{Roll} \\
\text{Pitch} \\
\text{Yaw}
\end{bmatrix}
= 
\begin{bmatrix}
\text{atan2} \left(2(q_w q_x + q_y q_z), 1-2(q_x^2 + q_y^2)  \right) \\
\text{asin} \left(2(q_w q_y - q_x q_z) \right) \\
\text{atan2} \left(2(q_w q_z + q_x q_y), 1-2(q_y^2 + q_z^2)  \right)
\end{bmatrix}
$$ {#eq-rpy}


Walking speed

: One of our hypothesis is that the subject gait can differ depending if the subject walks slowly of faster. Thus this variable was also added to the feature space by getting it from the GAITRite© mat output.

On the other hand, the feature space depends on two hyper-parameters. The first one is a smoothness parameter for the time-serie curves, as derivation is used to compute some variables. The second one is a lag parameter, to keep at the time $t_p$ the informations from the time $t_{p-1}$. That parameter implies that the feature space contains $10 + 9 \times lag$ variables.

Finally, the variable to be predicted contains the two possible classes *Hell-Strike* and *other times* from the GAITRite© mat output. We choose to label a number of points as *Hell-Strike* around the precise event time. This allows to take into account a some uncertainty, as the time range between two points is only 10 ms. By labelling as *Hell-Strike* seven points rather than just one, the event happens in a window of 70 ms. This strategy also reduces the imbalance between the two classes.


## Supervised classification models

# Tuning and comparing segmentation models

## Data splitting 

## Tuning strategy

## Performance metrics 

## Results

### Tuning of hyper-parameters

### Performances on the test set

# Discussion and conclusions





# References {.unnumbered}

::: {#refs}
:::
