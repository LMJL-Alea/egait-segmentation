---
title: "Gait Segmentation Model for Rotation Time Series Collected by a Wearable Sensor using Machine Learning"
author:
  - name: Manon Simonot
    corresponding: true
    email: manon.simonot@univ-nantes.fr
    affiliations:
      - name: Department of Mathematics Jean Leray, UMR CNRS 6629, Nantes University
  - name: Lise Bellanger
    email: lise.bellanger@univ-ubs.fr
    affiliations:
      - name: Lab-STICC Laboratory, UMR CNRS 6285, South Brittany University
  - name: Aymeric Stamm
    email: aymeric.stamm@cnrs.fr
    affiliations:
      - name: Department of Mathematics Jean Leray, UMR CNRS 6629, Nantes University
date: last-modified
date-modified: last-modified
abstract: >+
  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur posuere vestibulum facilisis. Aenean pretium orci augue, quis lobortis libero accumsan eu. Nam mollis lorem sit amet pelSlowsque ullamcorper. Curabitur lobortis libero eget malesuada vestibulum. Nam nec nibh massa. PelSlowsque porttitor cursus tellus. Mauris urna erat, rhoncus sed faucibus sit amet, venenatis eu ipsum.
keywords: [key1, key2, key3]
citation:
  type: article-journal
  container-title: "Computo"
  doi: "xxxx"
  url: https://computo.sfds.asso.fr/template-computo-quarto
  publisher: "Société Française de Statistique"
  issn: "2824-7795"
bibliography: references.bib
github-user: computorg
repo: "template-computo-r"
draft: true # set to false once the build is running
published: false # will be set to true once accepted
format:
  computo-html: default
  computo-pdf:
    cite-method: biblatex
    biblatexoptions: "sorting=none"
tbl-cap-location: bottom
header-includes:
  - \usepackage{longtable}
  - \usepackage{hhline}
  - \usepackage{enumitem}
---

# Introduction

## Context

### Gait analysis

Study of the human gait has been shown to be important in various health applications, such as study of general health in elderly populations [@beauchet2016poor]. Wearable sensors are increasingly used for gait analysis as they are smaller, cheaper and more convenient than other methods such as motion capture systems or mats containing pressure sensors.

A walking cycle is defined as a stride, which is composed of two steps. More formally, a stride is the set of movements performed between two consecutive contacts of the heel of the same foot with the ground. The goal of our method is to segment the gait as cycles to extract strides. This allows further study of the gait, like spatio-temporal parameters computation.

More precisely, a stride is divided in two phases: the stance phase and the swing phase. The stance phase lasts generally 60% of the entire stride. Different events are happening during a stride (see @fig-walking-cycle) and the focus in this work is the Heel-Strike event which will be the segmentation marker.

![Events and phases of a typical gait cycle. [^jacquelin-perry]](images/walking-cycles.png){#fig-walking-cycle width=400}

[^jacquelin-perry]: Figure annotated from Jaquelin Perry's one on [Wikipedia](https://commons.wikimedia.org/wiki/File:GaitCycle_by_JaquelinPerry.jpg).

### Unit quaternions

Unit quaternions can be used to represent the 3D rotation of an object over time [@hamilton1844;@voight2021quaternion]. This representation has several advantages, as it is a rather compressed representation containing only four values and avoiding the gimbal lock problem presents in other representations. Unit quaternions were therefore chosen as the data type returned by the sensor.

Quaternions are four-dimensional vectors denoted as $\mathbf{q} = \left( q_w, q_x, q_y, q_z \right)$, but can also be viewed as hypercomplex numbers of rank 4. Unit quaternions have a norm of 1 and can encode a 3D rotation with a rotation angle $\theta \in [0, 2\pi]$ and a rotation axis $\mathbf{u} = (u_x, u_y, u_z) \in S^2$, where $S^2$ is the 2-sphere, using the following formula:

$$
\mathbf{q} = \text{cos}\left(\frac{\theta}{2}\right) + \left(u_x i + u_y j + u_z k \right) \text{sin}\left(\frac{\theta}{2}\right)
$$ {#eq-quaternions}

with :

- $i$, $j$, and $k$ generalizing the imaginary number $i$, as $i^2=j^2=k^2=ijk=-1$.
- $||\mathbf{q}|| = \sqrt{\mathbf{qq}^t} = 1$.

The set of unit quaternions, denoted $\mathbb{H}_u$, possesses interesting properties. The quaternions $\mathbf{q}$ and $-\mathbf{q}$ represent the same rotation. The group is equipped with an identity element $\mathbf{q}^{(0)} = (1,0,0,0)$ which corresponds to the identity rotation, such that $\mathbf{q} \mathbf{q}^{(0)} = \mathbf{q}^{(0)}\mathbf{q} = \mathbf{q}$.

It is possible to use the geodesic distance $d_g$ between two quaternions $\mathbf{q}_1$ and $\mathbf{q}_2$ to define a metric space $(\mathbb{H}_u, d_g)$, with:

$$
d_g (\mathbf{q}_1, \mathbf{q}_2) = ||\text{log}(\mathbf{q}_1^{-1} \mathbf{q}_2)||
$$ {#eq-dist-geodesique}

In this application, the sensor orientation is the rotation between the reference frame of origin, here the Earth's reference frame $R_f=(f_1, f_2, f_3)$ and its own reference frame $R_s=(s_1, s_2, s_3)$ formed by the accelerometer, gyroscope, and magnetometer (see @fig-sensor-axis).

![Sensor reference and axis. [@drouin2023semi]](images/sensor-axis.png){#fig-sensor-axis width=200}

Therefore, the IMU returns unit quaternion time-series allowing the study of the 3D hip rotation over time, as four-component vectors.



## State of the art

In the past, several methods for gait cycle segmentation have been studied based on signals recorded from wearable sensors placed on different parts of the body. We try in this part to give an overview of proposed methods by grouping them into categories, with variations related to the position of sensors on the body, the type of sensor measurement system used, and the characteristics of the signal.

Search for feature points: Peak Detection and zero-crossing

: Peak detection algorithms exploit the semi-periodic properties of the gait cycle, assuming that specific events during a gait cycle typically match the maxima or minima of a recorded signal. Several algorithms based on this method have been developed. Spatio-temporal gait parameters have been determined from the acceleration signal of a sensor by using peak detection and zero-crossing methods to identify stride cycles [@zijlstra2003assessment]. Some peak detection algorithms have been developed to work on any kind of signal [@jiang2017robust] or are specifically implemented to work to detect gait events on a signal, often Heel-Strike on acceleration data [@lueken2019peak]. Most methods detect Heel-Strike and Toe-off events by identifying minima, maxima or zero-crossing of acceleration time series [@gonzalez2010real;@mariani2013quantitative;@panebianco2018analysis]. These events can be called Initial Contact and Terminal Contact and have also been identified on the foot inclination angle in the sagittal plane [@nazarahari2022foot].

Analysis of dynamic properties: Wavelet Transform

: To detect gait events in recorded signals, another used method is wavelet transform because it allows detection of a specified frequency at a specified time. This method has been used to detect Heel-Strike and Toe-off events on an angular velocity signal by using multi-resolution wavelet decomposition [@aminian2002spatio]. The signal is decomposed into wavelet packages, using high-scale and low-scale filters. In @mccamley2012enhanced, the signal of the vertical acceleration is smoothed by integrating and then differentiating using a Gaussian Continuous Wavelet Transform (CTW). Events are found on minima and maxima of the differentiated signal. Furthemore, a method called Sparsity-assisted wavelet denoising (SWAD) has been developed to segment the signal in three events: midstance, toe-off and heel-strike [@prateek2019gait]. It uses a combination of linear time invariant filters, wavelets and sparsity based methods to extract a coefficient vector of Discrete Wavelet Transform (DTW). That generates a sparse template of moving segments of gyroscope measurements.

Pattern-matching: Dynamic Time Warping (DTW)

: To segment signals, another method is pattern-matching. Dynamic Time Warping is widely used for this matter. It allows identification of patterns with different length and it matches signals non-linearly. Thus it is commonly used to evaluate the similarity between time series. This method has been used on an acceleration signal to identify gait cycles [@ghersi2020gait]. In another study, multi-dimensional subsequence DTW (msDTW) was used to segment strides using informations from different axes of an accelerometer and a gyroscope at the same time [@barth2015stride].

Hidden Markov Models

: Hidden Markov Models (HMMs) are machine learning models that can be used to simultaneously segment and classify data. In gait analysis, hidden states of the HMM are viewed as activity classes or gait phases. Continuous HMM with Gaussian mixture model are often used to model the outputs. Each cycle can be modeled with a circular left to right HMM, included in a more global HMM model to classify walking activities [@panahandeh2013continuous]. Other algorithms have the goal of detecting four gait events which are Heel-Strike, Flat-Foot, Heel-Off and Toe-Off. They use a four state left to right HMM with observations following a multivariate Gaussian distributions [@mannini2011hidden;@garcia2022adaptive]. Hierarchical HMMs have shown to perform better than Peak detection and Dynamic Time Warping algorithms on walking data [@haji2018segmentation].

Other Machine Learning methods

: Many studies on gait analysis use wearable sensors and machine learning. A study showed that most used methods for this purpose are SVM and CNN, and are largely used to detect diseases or recognize activities when analyzing gait data [@saboor2020latest]. SVM divides a set of objects into classes with widest possible margin at the hyperplane boundaries. Neural Networks use interconnected nodes organized in layers to process informations and learn patterns through back-propagation and make predictions using activation functions.

: Studies show good results when using machine learning to classify gait of patients having trouble walking, for instance patients with Parkinson Disease [@tahir2012parkinson;@wahid2015classification], or to extract gait parameters [@rampp2014inertial;@hannink2016sensor]. These studies mostly use Artificial Neural Networks but do not address the problem of the segmentation of the signal recorded by the sensors. Similarly, in @farah2019design, a logistic regression tree is used to classify gait phases in a stride but not to directly segment the signal into strides.

: For the segmentation matter, Recurrent Neural Networks have shown good results for identifying Heel-Strike and Toe-off events with pressure sensors, accelerations and Euler angles [@prado2019gait]. Another study compared unsupervised machine learning (k-means) with supervised one (SVM and CNN), showing that CNNs were performing the best to predict stance and swing phases [@potluri2019machine]. Lastly, in another study, 24 time series from three sensors’ accelerometers and gyroscopes were used as input into a 6 layers CNN to estimate the likelihood of the corresponding input sample, given a specific gait event [@gadaleta2019deep]. For instance, the signal can be segmented with the initial contact of the right foot if this gait event is chosen in the model. This method was shown to perform better than a Wavelet Transform algorithm.

In our research, we did not find studies using a decision tree model to segment the sensor signal into strides.


## Methologic contributions

   


# Proposed segmentation model

## Data acquisition

A wearable sensor was used to record the hip rotation. It contains an acceleromerer, a gyroscope and a magnetometer. Subjects were wearing the sensor on their right hip (see @fig-sensor-position). The frequence of the sensor is 100Hz. With this device, the data acquired is in the form of quaternion time-series, representing the 3D rotation of the hip over time.

![Sensor positionned on the right hip.](images/sensor-position.png){#fig-sensor-position width=150}


Furthemore, during acquisitions, subjects were walking on the GAITRite© mat, the gold standard in gait analysis [@Menz2004]. It implies that subject were walking approximately 9 meters. This device gives the times where the subjects touch the ground at each step thanks to pressure sensors in the mat, meaning that these times can be used to know when the Heel-Strike event actually happened. This data is then used to train the model. To use the two devices simultaneously, they were started at the same time by the same person, allowing a good synchronization between devices.

Six subjects have been included in this study, with different walking speed (see @tbl-subjects). 

<!-- +-----+--------+-------+-------------------------+ -->
<!-- | ID  | Gender | Age   | Speed (cm/s)            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MBA | M      | 50-60 | - Slow : 60             | -->
<!-- |     |        |       | - Intermediate : 116    | -->
<!-- |     |        |       | - Normal : 145          | -->
<!-- |     |        |       | - Fast : 199            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MBO | F      | 20-30 | - Slow : 73             | -->
<!-- |     |        |       | - Intermediate : 122    | -->
<!-- |     |        |       | - Normal : 145          | -->
<!-- |     |        |       | - Fast : 188            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MSI | F      | 20-30 | - Slow : 67             | -->
<!-- |     |        |       | - Intermediate : 115    | -->
<!-- |     |        |       | - Normal : 148          | -->
<!-- |     |        |       | - Fast : 179            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | MTR | M      | 20-30 | - Slow : 77             | -->
<!-- |     |        |       | - Normal : 132          | -->
<!-- |     |        |       | - Fast : 185            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | NNE | F      | 20-30 | - Slow :  57            | -->
<!-- |     |        |       | - Intermediate : 116    | -->
<!-- |     |        |       | - Normal : 147          | -->
<!-- |     |        |       | - Fast : 190            | -->
<!-- +=====+========+=======+=========================+ -->
<!-- | TDE | M      | 50-60 | - Slow : 61             | -->
<!-- |     |        |       | - Normal : 120          | -->
<!-- |     |        |       | - Fast : 193            | -->
<!-- +-----+--------+-------+-------------------------+ -->

<!-- : Summary of subjects and walking speeds used for the model. {#tbl-subjects} -->


::: {#tbl-subjects}

```{r}
data.frame(
  id = c("MBA", "MBO", "MSI", "MTR", "NNE", "TDE"),
  gender = c("M", "F", "F", "M", "F", "M"),
  age = c("50-60", "20-30", "20-30", "20-30", "20-30", "50-60"),
  slow = c(60, 73, 67, 77, 57, 61),
  intermediate = c(116, 122, 115, NA, 116, NA),
  preferential = c(145, 145, 148, 132, 147, 120),
  fast = c(199, 188, 179, 185, 190, 193)
) |> 
  gt::gt() |> 
  gt::tab_spanner(
    label = "Walking speed (cm/s)",
    columns = c(slow, intermediate, preferential, fast)
  ) |> 
  gt::cols_label(
    id = "ID",
    gender = "Gender",
    age = "Age range (years)",
    slow = "Slow",
    intermediate = "Intermediate",
    preferential = "Preferential",
    fast = "Fast"
  ) |> 
  gt::sub_missing() |> 
  gt::opt_stylize(style = 6, color = 'gray') |> 
  gt::cols_align(align = "center") |> 
  gt::tab_style(
    style = "vertical-align:top", 
    locations = gt::cells_column_labels()
  )
```

Summary of subjects and walking speeds used for the model.

:::


## Data presentation

Sensor data

: As mentioned before, the sensor returns unit quaternion time-series representing the rotation of the hip over time, allowing visualization of each coordinate time-serie (see @fig-timeserie). It is important to note that on this figure, the walking cycles are clearly apparent and consistent over time, as it represents a healthy gait. This is not the case for subjects having gait disorders, which is why we develop a method more complex than peak detection.

![Data returned by the wearable sensor.](images/time-serie.png){#fig-timeserie width=350}

Sensor data preprocessing 

: A centring step is applied on the quaternion time-series to center them around a mean. Supposing we have $n$ time-series $\mathbf{Q}_1, \dots, \mathbf{Q}_n$ on the same time grid $t_1, \dots, t_p$, we can write $\mathbf{Q}_i(t_k) = \mathbf{q}_{ik} \in \mathbb{H}_u$, with $i \in [\![ 1, n ]\!]$ et $k \in [\![ 1, p ]\!]$. We use the Fréchet mean associated to the geodesic distance $d_g$ (see @eq-dist-geodesique) to compute the mean of each quaternion $\mathbf{q}_{1k}, \dots, \mathbf{q}_{nk}$ for each time $t_k$. 

: $$
\mathbf{q}_k^{(m)} = \mathbf{Q}^{(m)} (t_k) = \underset{q \in \mathbb{H}_u}{\mathrm{argmin}} \sum_{i=1}^n d_g^2(\mathbf{q}_{ik}, \mathbf{q}), \hspace{5mm} k \in [\![ 1, p ]\!]
$$ {#eq-mean-qts}

: The centered time-series $\mathbf{Q}_1^{(c)}, \dots, \mathbf{Q}_n^{(c)}$ can then be computed.

: $$
\mathbf{q}_{ik}^{(c)} = \mathbf{Q}_i^{(c)} (t_k) = \left( \mathbf{q}_k^{(m)} \right)^{-1} \mathbf{q}_{ik}, \hspace{5mm} k \in [\![ 1, p ]\!],\hspace{2mm}  i \in [\![ 1, n ]\!]
$$ {#eq-centring-qts}

: The other pre-processing step is to switch to a functional representation using cubic splines to be able to compute derivatives [@ramsay2005].


Pressure mat data

: The GAITRite© mat returns directly spatio-temporal parameters such as stride duration, stride length or speed. The key parameter in our study is the Heel-Strike exact time. Since the two devices were triggered simultaneously, the same time range is used to associate the Heel-Strike event with a time on the sensor time-series. More precisely, each time of the time-series will be classified between two classes: *Heel-Strike* or *other times*. This method rises a class imbalance challenge that will be adressed later in the article.


## Feature space

To implement a machine learning model, we build a feature space containing variables characterizing the hip rotation over time.

Angular velocity and acceleration

: Supposing we can compute first and second derivatives of a quaternion time-series over time, we can compute angular velocity and acceleration [@narayan2017]. The angular velocity $\pmb{\Omega}$ is a vector which has for direction the axis of rotation and for quantity the angular velocity.

: $$
\pmb{\Omega} = 2 \mathbf{q}^{-1} \dot{\mathbf{q}} \hspace{3mm} \text{with} \hspace{3mm} \dot{\mathbf{q}} = \frac{d \mathbf{q}}{dt} = \frac{1}{2} \mathbf{q} \hspace{1mm} \pmb{\Omega}
$$ {#eq-angular-vel}

: Similarly, the angular acceleration $\dot{\pmb{\Omega}}$ is the angular velocity derivative.

: $$
\dot{\pmb{\Omega}} = 2 \left( \mathbf{q}^{-1} \ddot{\mathbf{q}} - (\mathbf{q}^{-1}\dot{\mathbf{q}})^2 \right) \hspace{3mm} \text{with} \hspace{3mm} \ddot{\mathbf{q}} = \frac{d^2 \mathbf{q}}{dt^2} = \frac{1}{2} \left( \dot{\mathbf{q}} \hspace{1mm}  \pmb{\Omega} + \mathbf{q} \hspace{1mm}  \dot{\pmb{\Omega}} \right)
$$ {#eq-angular-acc}

Euler angles

: The angles named Roll, Pitch and Yaw represent rotations around the three principal axies. Their computation is done using the quaternion time-series, with the following rotation matrix to go from the quaternion $\mathbf{q} = (q_w, q_x, q_y, q_z)$ to the angles.

$$
\begin{bmatrix}
\text{Roll} \\
\text{Pitch} \\
\text{Yaw}
\end{bmatrix}
= 
\begin{bmatrix}
\text{atan2} \left(2(q_w q_x + q_y q_z), 1-2(q_x^2 + q_y^2)  \right) \\
\text{asin} \left(2(q_w q_y - q_x q_z) \right) \\
\text{atan2} \left(2(q_w q_z + q_x q_y), 1-2(q_y^2 + q_z^2)  \right)
\end{bmatrix}
$$ {#eq-rpy}


Walking speed

: One of our hypothesis is that the subject gait can differ depending if the subject walks slowly of faster. Thus this variable was also added to the feature space by getting it from the GAITRite© mat output.

On the other hand, the feature space depends on two hyper-parameters. The first one is a smoothness parameter for the time-serie curves, as derivation is used to compute some variables. The second one is a lag parameter, to keep at the time $t_p$ the informations from the time $t_{p-1}$. That parameter implies that the feature space contains $10 + 9 \times lag$ variables.

Finally, the variable to be predicted contains the two possible classes *Heel-Strike* and *other times* from the GAITRite© mat output. We choose to label a number of points as *Heel-Strike* around the precise event time. This allows to take into account a some uncertainty, as the time range between two points is only 10 ms. By labelling as *Heel-Strike* seven points rather than just one, the event happens in a window of 70 ms. This strategy also reduces the imbalance between the two classes.


## Supervised classification models

Decision tree

: Decision trees consist of a nested sequence of if-then statements for the predictor classifying data. Observations are assigned to their class according to the variable values. Here is a figure of a tree with two splitting, leading to three leaf nodes. 

: ![Basic decision tree.](images/decision-tree.png){#fig-decisiontree width=250}

: The goal is to classify the observations into smaller and more homogenous groups, forming rectangular areas within data points. Homogeneity is defined here as how pure are the splitting nodes [@kuhn2013applied], meaning that there is a higher proportion of one class in each node. We can use the Gini index [@breiman2017classification] to compute purity. For a binary classification, if $p1$ and $p2$ are the probabilities for class 1 and 2 respectively, the Gini index for a node computed with the formula:

: $$
\text{Gini} = p_1(1-p_1) + p_2(1-p_2) = 2p_1p_2
$${#eq-gini}

: This index is minimal when one of the probabilities tends toward zero, indicating that the node is pure. To build the tree, the model builds splitting nodes by evaluating each splitting point (ie values taken by variables to split observations into groups) to find the one minimizing the Gini index, until a stopping criteria is met.

Bagged trees and Random forest [@kuhn2013applied]

: A bagged trees model is an ensemble of $M$ decision trees. Each decision tree is built with a boostrap sample of the original data, which is a sample of same size than the original data by selecting random observations with replacement. Then, each of these trees is used to generate a prediction for a new observation. Finally, the observation is classified in the class that has collected the greatest number of votes from the trees.

: A random forest is a quite similar model, also using a number of decision trees. The model also train a tree on a boostrap sample of the original data. The difference is that, at each split, a random subset of the variables is selected to then find the best predictors within this subset. The observations are then classified as usual. The prediction is done the same way as seen before, with each tree voting for a class and selecting the majority to classify the observation.


Neural networks [@varma2018]

: Neural Networks are deep learning models inspired by the human brain. They consist of interconnected nodes organized in layers which process the data by passing it from one layer to the next. The input data is transformed with non-linear functions, allowing the model to return a classification for each observation as output. The model contains two essential parameters: weights on each connection and biases on each node. It learns data pattern by adjusting these parameters during forward and backward propagation for each observation to mimimize a loss that represents the difference between real and predicted values. Most often, the loss used is the cross-entropy which is defined as followed for the observation $m$:

: $$
\square(m) = - \sum_{k=1}^K t_k(m) \text{log}(y_k(m))
$$ {#eq-crossentropy}

: with:

: - $t_k$ the ground truth.
: - $ny_k$ the classification probability.

: These models are complex and rely on a performant algorithm for the parameter update and an adapted activation function, as well as possible utilisation of batch normalization and regularization to find a model with a good complexity for the data. Tuning is done to find the best hyper-parameters such as the number of layers and nodes and the learning rate.


# Tuning and comparing segmentation models

## Dealing with imbalanced data

By classifiying specific times in a time serie, we work with imbalanced data, meaning that a small proportion of our data is in the target class, and most of the data points are in the other class. In this situation, the model learns adequate informations about the majority class but doesn't have enough information on the minority class. This implies bad predictions on the target class because the model misses this class.

A lot of sampling algorithms exist to adress this issue such as random oversampling or random undersampling which add or remove observations from certain classes to create a balanced dataset. More complex methods exist, we can cite the popular SMOTE [@chawla2002] and ADASYN [@haibo2008] algorithms that create synthetic data by considering the classes of the nearest neighbors of random observations. Although these algorithms are very popular, they did not show good results for our data. We are making the hypothesis that our data is too imbalanced for these methods.

To tell the model to pay more attention to the patterns in the minority class, an effective way is to put a larger weight on this class. More precisely, the weight given to each observation specifies how much each observation influences the model's estimation In order for the model to be biased in favor of the observations considered more important, in our case those belonging to the minority class, the weights of the observations are integrated into the cost function. This makes it possible to regulate the cost of misclassification, in the sense that misclassifying more important observations will be more costly, encouraging the model to avoid this situation [@hashemi2018].

Weights put on classes are the inverse class frequency weights. The weight on the class $j$ is the following:

$$
\omega_j = \frac{n}{n_{classes} \hspace{1mm} n_j}
$$ {#eq-inv-class-frequency}

with:

- $n$ the total number of observations.
- $n_{classes}$ the number of classes.
- $n_j$ the number of observations in the class $j$.

This formula gives balanced weights at the different classes to pay better attention at the minority class.


## Performance metrics 

In the case of imbalanced class, we cannot use accucary to correctly evaluate the model. Indeed, since the model will predict almost only the majority class, the predictions in this class will be good, implying that the accuracy will be high because most of the observations will be well-classified. This does not take into account the observations in the minority class which are not predicted.

We need to use other metrics that are adapted for this situation. An important tool is the confusion matrix which indicate the number of predictions in each class compared to the real values of the observations.

*Here, either metric for binary or multiclass*



## Data splitting and Tuning strategy

To correctly tune and evaluate the model, data is split in three sets (see @fig-datasplitting).

![Data splitting.](images/data-splitting.png){#fig-datasplitting width=300}

During tuning and training, the training set is used to train the model and the validation set is used to find the best parameters. The test set is never used during the training step to then evaluate the model on data never seen before. 

More precisely, for a neural network, we first use the training set to train the parameters (the weights and the biases of the network). Then, we use the validation set to determine the hyper-parameters (for instance, the number of layers and nodes). Finally, we use the test set to evaluate the model on unseen data.

To tune hyper-parameters, automated tuning was used by grid search which is an exhaustive search in the hyper-parameter space. For each of our parameter, we set a grid of values to be tested. Every combination of the values is then evaluated to get the best possible combination of hyper-parameter values.

## Results

### Tuning of hyper-parameters

### Performances on the test set

# Discussion and conclusions





# References {.unnumbered}

::: {#refs}
:::
